{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUE+gEGvEqtoTMIeMI3Pah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimelightVision/notebooks/blob/main/limelight-tfrecord-unpacker-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![UnpackerNotebookLogo](https://ik.imagekit.io/llimi/docs/UnpackerNotebookLogo.png?updatedAt=1739507557283)"
      ],
      "metadata": {
        "id": "5C9a2XUiu8c0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Upload your RoboFlow .tfrecord.zip to Google Drive\n",
        "2. Share the uploaded .tfrecord.zip such that anyone with the link can access the file.\n",
        "3. Run this block\n",
        "4. Paste your Google Drive file share link into the text box that appears after running this block\n",
        "5. Click the \"Process Dataset\" Buttton\n",
        "6. Click the Refresh button in the \"Files\" pane to ensure dataset.zip exists"
      ],
      "metadata": {
        "id": "FQMc0P0KJaOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "from IPython.display import display\n",
        "from ipywidgets import Text, Button, VBox\n",
        "\n",
        "def process_dataset():\n",
        "    link_input = Text(\n",
        "        value='',\n",
        "        placeholder='Paste your Google Drive share link here',\n",
        "        description='Drive Link:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': '50%'}\n",
        "    )\n",
        "\n",
        "    def on_click(b):\n",
        "        try:\n",
        "            print(\"Downloading dataset...\")\n",
        "            url = link_input.value\n",
        "\n",
        "            if 'drive.google.com/file/d/' in url:\n",
        "                file_id = url.split('/file/d/')[1].split('/')[0]\n",
        "                url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "            output = '/content/dataset.zip'\n",
        "            gdown.download(url, output, fuzzy=True)\n",
        "            print(\"Download complete!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")\n",
        "\n",
        "    process_button = Button(description='Process Dataset', button_style='primary')\n",
        "    process_button.on_click(on_click)\n",
        "    display(VBox([link_input, process_button]))\n",
        "\n",
        "# Install gdown if not already installed\n",
        "!pip install -q gdown --upgrade\n",
        "\n",
        "# Execute\n",
        "process_dataset()"
      ],
      "metadata": {
        "id": "vd6lPH2lqvcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the archive"
      ],
      "metadata": {
        "id": "rR8KlISoJe-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasetPath = '/content/dataset.zip'\n",
        "print(datasetPath)\n",
        "!unzip $datasetPath"
      ],
      "metadata": {
        "id": "tTPB93qLrTPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display a few images from the training set"
      ],
      "metadata": {
        "id": "bIVmZrLzJhfd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uKFJgRzqcP0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def find_files(directory, pattern):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for basename in files:\n",
        "            if fnmatch.fnmatch(basename, pattern):\n",
        "                filename = os.path.join(root, basename)\n",
        "                yield filename\n",
        "\n",
        "def set_tfrecord_variables(directory):\n",
        "    train_record_fname = ''\n",
        "    val_record_fname = ''\n",
        "    label_map_pbtxt_fname = ''\n",
        "\n",
        "    for tfrecord_file in find_files(directory, '*.tfrecord'):\n",
        "        if '/train/' in tfrecord_file:\n",
        "            train_record_fname = tfrecord_file\n",
        "        elif '/valid/' in tfrecord_file:\n",
        "            val_record_fname = tfrecord_file\n",
        "        elif '/test/' in tfrecord_file:\n",
        "            pass\n",
        "\n",
        "    for label_map_file in find_files(directory, '*_label_map.pbtxt'):\n",
        "        label_map_pbtxt_fname = label_map_file  # Assuming one common label map file\n",
        "\n",
        "    return train_record_fname, val_record_fname, label_map_pbtxt_fname\n",
        "\n",
        "\n",
        "train_record_fname, val_record_fname, label_map_pbtxt_fname = set_tfrecord_variables('/content')\n",
        "\n",
        "\n",
        "print(\"Train Record File:\", train_record_fname)\n",
        "print(\"Validation Record File:\", val_record_fname)\n",
        "print(\"Label Map File:\", label_map_pbtxt_fname)\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "\n",
        "def parse_tfrecord(example_proto):\n",
        "    \"\"\"Parse the input tf.Example proto including bounding box information.\"\"\"\n",
        "    feature_description = {\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
        "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/width': tf.io.FixedLenFeature([], tf.int64)\n",
        "    }\n",
        "    return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "def decode_image(parsed_features):\n",
        "    \"\"\"Decode the image from parsed features.\"\"\"\n",
        "    image = tf.io.decode_image(parsed_features['image/encoded'])\n",
        "    return image\n",
        "\n",
        "def get_bboxes(parsed_features):\n",
        "    \"\"\"Extract bounding boxes from parsed features.\"\"\"\n",
        "    xmin = tf.sparse.to_dense(parsed_features['image/object/bbox/xmin'])\n",
        "    xmax = tf.sparse.to_dense(parsed_features['image/object/bbox/xmax'])\n",
        "    ymin = tf.sparse.to_dense(parsed_features['image/object/bbox/ymin'])\n",
        "    ymax = tf.sparse.to_dense(parsed_features['image/object/bbox/ymax'])\n",
        "    labels = tf.sparse.to_dense(parsed_features['image/object/class/label'])\n",
        "\n",
        "    return {\n",
        "        'xmin': xmin.numpy(),\n",
        "        'xmax': xmax.numpy(),\n",
        "        'ymin': ymin.numpy(),\n",
        "        'ymax': ymax.numpy(),\n",
        "        'labels': labels.numpy()\n",
        "    }\n",
        "\n",
        "def draw_bboxes(ax, bboxes, image_height, image_width):\n",
        "    \"\"\"Draw bounding boxes on the image.\"\"\"\n",
        "    colors = plt.cm.hsv(np.linspace(0, 1, 20))\n",
        "\n",
        "    for i in range(len(bboxes['xmin'])):\n",
        "        xmin = bboxes['xmin'][i] * image_width\n",
        "        xmax = bboxes['xmax'][i] * image_width\n",
        "        ymin = bboxes['ymin'][i] * image_height\n",
        "        ymax = bboxes['ymax'][i] * image_height\n",
        "\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        rect = patches.Rectangle(\n",
        "            (xmin, ymin), width, height,\n",
        "            linewidth=2,\n",
        "            edgecolor=colors[bboxes['labels'][i] % len(colors)],\n",
        "            facecolor='none'\n",
        "        )\n",
        "\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        ax.text(\n",
        "            xmin, ymin - 5,\n",
        "            f'Class {bboxes[\"labels\"][i]}',\n",
        "            color=colors[bboxes['labels'][i] % len(colors)],\n",
        "            bbox=dict(facecolor='white', alpha=0.8)\n",
        "        )\n",
        "\n",
        "def display_images(tfrecord_path, num_images=5):\n",
        "    \"\"\"Display images from a TFRecord file with bounding boxes.\"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    dataset = dataset.map(parse_tfrecord)\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 5*num_images))\n",
        "\n",
        "    for i, parsed_features in enumerate(dataset.take(num_images)):\n",
        "        image = decode_image(parsed_features)\n",
        "        bboxes = get_bboxes(parsed_features)\n",
        "\n",
        "        height = parsed_features['image/height'].numpy()\n",
        "        width = parsed_features['image/width'].numpy()\n",
        "\n",
        "        ax = plt.subplot(num_images, 1, i+1)\n",
        "        plt.imshow(image.numpy())\n",
        "        draw_bboxes(ax, bboxes, height, width)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Image {i+1}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_single_image(tfrecord_path, image_index=0):\n",
        "    \"\"\"Display a single image from a TFRecord file with bounding boxes.\"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    dataset = dataset.map(parse_tfrecord)\n",
        "\n",
        "    for i, parsed_features in enumerate(dataset):\n",
        "        if i == image_index:\n",
        "            image = decode_image(parsed_features)\n",
        "            bboxes = get_bboxes(parsed_features)\n",
        "\n",
        "            height = parsed_features['image/height'].numpy()\n",
        "            width = parsed_features['image/width'].numpy()\n",
        "\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            ax = plt.gca()\n",
        "            plt.imshow(image.numpy())\n",
        "            draw_bboxes(ax, bboxes, height, width)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "tfrecord_path = train_record_fname\n",
        "display_images(tfrecord_path, num_images=50)\n",
        "# Example usage for single image:\n",
        "# display_single_image(tfrecord_path, image_index=0)"
      ]
    }
  ]
}